{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef3f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118656bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r \"C:\\Users\\DELL\\Desktop\\trainwhatasppllm\\requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1079b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0771fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import BasicTokenizer\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.load(model_file=r\"C:\\Users\\DELL\\Desktop\\trainwhatasppllm\\output\\tokenizer\\my_tokenizer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cace7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(tokenizer:BasicTokenizer) -> int:\n",
    "    vocab = tokenizer.vocab\n",
    "    special_token = tokenizer.special_tokens\n",
    "\n",
    "    return len(vocab) + len(special_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c172c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(3647)\n",
    "\n",
    "block_size = 256\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "vocab_size = get_vocab_size(tokenizer)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae297153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size:int) -> None:\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x:torch.Tensor, mask:Optional[torch.Tensor]=None) -> torch.Tensor:\n",
    "        _,T,_ = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        weights = q @ k.transpose(-2, -1) * (k.shape[-1] ** -0.5)\n",
    "        weights = weights.masked_fill(self.tril[:T, :T]==0, float('-inf'))\n",
    "\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        v = self.value(x)\n",
    "        out = weights @ v\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads:int, head_size:int)-> None:\n",
    "        super().__init__()\n",
    "        self.head = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.projection = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.projection(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747ee9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd: int) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd: int, n_head:int) -> None:\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.self_attention = MultiHeadAttention(n_head, head_size)\n",
    "        self.feed_forward = FeedFoward(n_embd)\n",
    "        self.layer_norm_1 = nn.LayerNorm(n_embd)\n",
    "        self.layer_norm_2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.self_attention(self.layer_norm_1(x))\n",
    "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eba0c81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGPTLanguageModel\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      4\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.final_layer_norm = nn.LayerNorm(n_embd)\n",
    "        self.final_linear_layer = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module: nn.Module) -> None:\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean= 0.0, std=0.02)\n",
    "\n",
    "    def forward(self, input_tokens: torch.Tensor, targets: Optional[torch.Tensor] = None) ->Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            input_tokens: Tensor of token indices of shape (batch_size, sequence_length)\n",
    "            targets: Optional tensor of target token indices of same shape as input_tokens\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (logits, loss) where logits has shape (batch_size, sequence_length, vocab_size)\n",
    "            and loss is optional cross-entropy loss if targets are provided\n",
    "        \"\"\"\n",
    "\n",
    "        B, T = input_tokens.shape\n",
    "\n",
    "        token_embedding = self.token_embedding_table(input_tokens)\n",
    "        positional_embedding = self.position_embedding_table(\n",
    "            torch.arrange(T, device=device)\n",
    "        )\n",
    "        x = token_embedding + positional_embedding\n",
    "        x = self.blocks(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "        logits = self.final_linear_layer(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, input_tokens: torch.Tensor, max_new_tokens:int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "                Generate new tokens given a context.\n",
    "\n",
    "                Args:>ns: Starting token indices of shape (batch_size, sequence_length)\n",
    "                        max_new_tokens: Number of new tokens to generate\n",
    "\n",
    "                Returns:\n",
    "                        Tensor of token indices of shape (batch_size, sequence_length + max_new_tokens)\n",
    "                \"\"\"\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "\n",
    "            cropped_input = input_tokens[:, -block_size]\n",
    "\n",
    "            logits, _ = self(cropped_input)\n",
    "\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            probs = F.softmax(logits, dim= -1)\n",
    "\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            input_tokens = torch.cat(\n",
    "                (input_tokens, idx_next), dim=1\n",
    "            )\n",
    "\n",
    "        return input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffaebcba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPTLanguageModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mGPTLanguageModel\u001b[49m()\n\u001b[32m      2\u001b[39m model  = model.to(device)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(p.numel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model.parameters())/\u001b[32m1e6\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mM parameters\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'GPTLanguageModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel()\n",
    "model  = model.to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1383d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m batch_size = \u001b[32m1\u001b[39m\n\u001b[32m      2\u001b[39m seq_length = \u001b[32m6\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m x = \u001b[43mtorch\u001b[49m.randint(\u001b[32m0\u001b[39m, vocab_size, (batch_size, seq_length))\n\u001b[32m      5\u001b[39m logits, loss = model(x)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(logits.shape, loss)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_length = 6\n",
    "x = torch.randint(0, vocab_size, (batch_size, seq_length))\n",
    "\n",
    "logits, loss = model(x)\n",
    "print(logits.shape, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86636b1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_model_structure\u001b[39m(model: \u001b[43mtorch\u001b[49m.nn.Module, indent: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Custom function to print model structure in a hierarchical format\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m model.named_children():\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def print_model_structure(model: torch.nn.Module, indent: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Custom function to print model structure in a hierarchical format\n",
    "    \"\"\"\n",
    "    for name, child in model.named_children():\n",
    "        params = sum(p.numel() for p in child.parameters())\n",
    "        print(f\"{indent}├─ {name}: {child.__class__.__name__} ({params:,} parameters)\")\n",
    "        print_model_structure(child, indent + '│  ')\n",
    "\n",
    "\n",
    "print_model_structure(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094ce9b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model_stats\u001b[39m(model: \u001b[43mtorch\u001b[49m.nn.Module) -> pd.DataFrame:\n\u001b[32m      5\u001b[39m     stats=[]\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, module, \u001b[38;5;129;01min\u001b[39;00m model.named_modules():\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_model_stats(model: torch.nn.Module) -> pd.DataFrame:\n",
    "\n",
    "    stats=[]\n",
    "    for name, module, in model.named_modules():\n",
    "        if len(list(module.children())) == 0:\n",
    "            params = sum(p.numel() for p in module.parameters())\n",
    "            stats.append({\n",
    "                'Layer Name': name,\n",
    "                'Type': module.__class__.__name__,\n",
    "                'Parameters': params,\n",
    "                'Trainable': sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "            })\n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "stats_df = get_model_stats(model)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add00cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
